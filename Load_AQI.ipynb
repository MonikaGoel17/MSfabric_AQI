{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","import requests\n","from pyspark.sql.functions import current_timestamp\n","\n","\n","# Create a Spark session\n","spark = SparkSession.builder.appName(\"Fetch Air Quality Data\").getOrCreate()\n","\n","# Load the `capitals_coordinates` table from the Lakehouse\n","# Assuming the Lakehouse path is `/lakehouse/default/Tables/capitals_coordinates`\n","capitals_df = spark.read.format(\"delta\").load(\"Tables/capitals_coordinates\")\n","\n","# Show the contents of the table\n","#capitals_df.show()\n","\n","# Define the WAQI API token\n","API_TOKEN = \"88e4c4c4e8c0d62b6e8f46ff909d340e796d28f6\"\n","\n","# API endpoint\n","BASE_URL = \"https://api.waqi.info/feed/geo:{lat};{lon}/?token={token}\"\n","\n","# Function to fetch data from the API\n","def fetch_air_quality(row):\n","    try:\n","        # Construct the API URL\n","        url = BASE_URL.format(lat=row[\"Latitude\"], lon=row[\"Longitude\"], token=API_TOKEN)\n","        \n","        # Make the API request\n","        response = requests.get(url)\n","        \n","        # Parse the API response\n","        if response.status_code == 200:\n","            result = response.json()\n","            if result.get(\"status\") == \"ok\":\n","                data = result.get(\"data\", {})\n","                return {\n","                    \"Country\": row[\"Country\"],\n","                    \"Capital_City\": row[\"Capital_City\"],\n","                    \"Latitude\": row[\"Latitude\"],\n","                    \"Longitude\": row[\"Longitude\"],\n","                    \"AQI\": data.get(\"aqi\"),\n","                    \"Dominant_Pollutant\": data.get(\"dominentpol\"),\n","                    \"Timestamp\": data[\"time\"][\"s\"]\n","                }\n","        # Return error information if API call fails\n","        return {\n","            \"Country\": row[\"Country\"],\n","            \"Capital_City\": row[\"Capital_City\"],\n","            \"Latitude\": row[\"Latitude\"],\n","            \"Longitude\": row[\"Longitude\"],\n","            \"Error\": response.text\n","        }\n","    except Exception as e:\n","        # Return error details\n","        return {\n","            \"Country\": row[\"Country\"],\n","            \"Capital_City\": row[\"Capital_City\"],\n","            \"Latitude\": row[\"Latitude\"],\n","            \"Longitude\": row[\"Longitude\"],\n","            \"Error\": str(e)\n","        }\n","\n","# Convert the DataFrame rows to RDD for parallel processing\n","capitals_rdd = capitals_df.rdd.map(lambda row: fetch_air_quality(row.asDict()))\n","\n","# Convert the RDD back to a Spark DataFrame\n","air_quality_df = spark.createDataFrame(capitals_rdd)\n","\n","# Add the ADT_Created_DTM column with the current datetime\n","air_quality_df = air_quality_df.withColumn(\"ADT_Created_DTM\", current_timestamp())\n","\n","# Show the resulting DataFrame\n","air_quality_df.show(truncate=False)\n","\n","# Save the results to the Lakehouse\n","air_quality_df.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").format(\"delta\").saveAsTable(\"Capitals_air_quality_Index\")\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"a9ad431a-701a-4bbe-9cae-b87b2d4b47cd","normalized_state":"finished","queued_time":"2024-11-24T13:55:09.6382743Z","session_start_time":null,"execution_start_time":"2024-11-24T13:55:10.2081734Z","execution_finish_time":"2024-11-24T14:00:00.1951367Z","parent_msg_id":"37789c38-3de7-4cac-b92c-909c516b5545"},"text/plain":"StatementMeta(, a9ad431a-701a-4bbe-9cae-b87b2d4b47cd, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+---+---------------------+-------------------+------------------+--------+---------+-------------------+--------------------------+\n|AQI|Capital_City         |Country            |Dominant_Pollutant|Latitude|Longitude|Timestamp          |ADT_Created_DTM           |\n+---+---------------------+-------------------+------------------+--------+---------+-------------------+--------------------------+\n|164|Kabul                |Afghanistan        |pm25              |34.5289 |69.1725  |2024-11-24 17:00:00|2024-11-24 13:55:17.038454|\n|23 |Tiranë (Tirana)      |Albania            |o3                |41.3275 |19.8189  |2024-11-24 14:00:00|2024-11-24 13:55:17.038454|\n|85 |El Djazaïr  (Algiers)|Algeria            |pm25              |36.7525 |3.042    |2024-11-24 13:00:00|2024-11-24 13:55:17.038454|\n|5  |Pago Pago            |American Samoa     |pm25              |-14.2781|-170.7025|2024-11-24 02:00:00|2024-11-24 13:55:17.038454|\n|18 |Andorra la Vella     |Andorra            |pm25              |42.5078 |1.5211   |2024-11-24 14:00:00|2024-11-24 13:55:17.038454|\n|58 |Luanda               |Angola             |pm25              |-8.8368 |13.2343  |2024-11-24 14:00:00|2024-11-24 13:55:17.038454|\n|11 |The Valley           |Anguilla           |pm25              |18.217  |-63.0578 |2024-11-24 08:00:00|2024-11-24 13:55:17.038454|\n|14 |St. John's           |Antigua and Barbuda|pm10              |17.1172 |-61.8457 |2024-11-24 09:00:00|2024-11-24 13:55:17.038454|\n|42 |Buenos Aires         |Argentina          |pm25              |-34.6051|-58.4004 |2024-11-24 09:00:00|2024-11-24 13:55:17.038454|\n|162|Yerevan              |Armenia            |pm25              |40.182  |44.5146  |2024-11-24 16:00:00|2024-11-24 13:55:17.038454|\n|25 |Oranjestad           |Aruba              |pm25              |12.524  |-70.027  |2024-11-24 07:00:00|2024-11-24 13:55:17.038454|\n|22 |Canberra             |Australia          |pm25              |-35.2835|149.1281 |2024-11-24 22:00:00|2024-11-24 13:55:17.038454|\n|46 |Wien (Vienna)        |Austria            |pm25              |48.2064 |16.3707  |2024-11-24 14:00:00|2024-11-24 13:55:17.038454|\n|142|Baku                 |Azerbaijan         |pm25              |40.3777 |49.892   |2024-11-24 16:00:00|2024-11-24 13:55:17.038454|\n|21 |Nassau               |Bahamas            |pm25              |25.0582 |-77.3431 |2024-11-24 08:00:00|2024-11-24 13:55:17.038454|\n|74 |Al-Manamah (Manama)  |Bahrain            |pm25              |26.2154 |50.5832  |2024-11-24 14:00:00|2024-11-24 13:55:17.038454|\n|194|Dhaka                |Bangladesh         |pm25              |23.7104 |90.4074  |2024-11-24 17:00:00|2024-11-24 13:55:17.038454|\n|14 |Bridgetown           |Barbados           |o3                |13.1    |-59.6167 |2024-11-24 09:00:00|2024-11-24 13:55:17.038454|\n|23 |Minsk                |Belarus            |o3                |53.9    |27.5667  |2024-11-24 14:00:00|2024-11-24 13:55:17.038454|\n|23 |Bruxelles-Brussel    |Belgium            |o3                |50.8467 |4.3499   |2024-11-24 14:00:00|2024-11-24 13:55:17.038454|\n+---+---------------------+-------------------+------------------+--------+---------+-------------------+--------------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":2,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6ebbb896-2d32-41a3-8799-af3ace1c6305"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"56f9ac85-9655-4213-a5b7-d88b49a5cf9c","known_lakehouses":[{"id":"56f9ac85-9655-4213-a5b7-d88b49a5cf9c"}],"default_lakehouse_name":"MyLakehouse","default_lakehouse_workspace_id":"043c4f4c-0d26-40d7-a2ab-6e394098e10a"}}},"nbformat":4,"nbformat_minor":5}